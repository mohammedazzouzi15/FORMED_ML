{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-09-14 00:05:12,570] Using an existing study with name 'equiformer_v2' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:12 (WARNING): Overwritten config parameters from included configs (non-included parameters take precedence): ['trainer']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:12 (INFO): Setting env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
      "2024-09-14 00:05:12 (INFO): Project root: /media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem\n",
      "2024-09-14 00:05:13 (INFO): amp: false\n",
      "cmd:\n",
      "  checkpoint_dir: ./checkpoints/2024-09-14-00-04-48\n",
      "  commit: null\n",
      "  identifier: ''\n",
      "  logs_dir: ./logs/wandb/2024-09-14-00-04-48\n",
      "  print_every: 10\n",
      "  results_dir: ./results/2024-09-14-00-04-48\n",
      "  seed: 0\n",
      "  timestamp_id: 2024-09-14-00-04-48\n",
      "  version: 1.1.0\n",
      "dataset:\n",
      "  a2g_args:\n",
      "    r_data_keys:\n",
      "    - S1_exc\n",
      "    r_energy: false\n",
      "    r_forces: false\n",
      "  format: ase_db\n",
      "  include_relaxed_energy: false\n",
      "  keep_in_memory: false\n",
      "  key_mapping:\n",
      "    S1_exc: energy\n",
      "  src: /media/mohammed/Work/FORMED_ML/train/formed_train.db\n",
      "evaluation_metrics:\n",
      "  metrics:\n",
      "    energy:\n",
      "    - mae\n",
      "    - mse\n",
      "  primary_metric: energy_mae\n",
      "gp_gpus: null\n",
      "gpus: 1\n",
      "logger: wandb\n",
      "loss_functions:\n",
      "- energy:\n",
      "    fn: mae\n",
      "model:\n",
      "  alpha_drop: 0.1\n",
      "  attn_activation: silu\n",
      "  attn_alpha_channels: 64\n",
      "  attn_hidden_channels: 64\n",
      "  attn_value_channels: 16\n",
      "  distance_function: gaussian\n",
      "  drop_path_rate: 0.05\n",
      "  edge_channels: 128\n",
      "  ffn_activation: silu\n",
      "  ffn_hidden_channels: 128\n",
      "  grid_resolution: 18\n",
      "  lmax_list:\n",
      "  - 6\n",
      "  max_neighbors: 20\n",
      "  max_num_elements: 90\n",
      "  max_radius: 12.0\n",
      "  mmax_list:\n",
      "  - 2\n",
      "  name: equiformer_v2\n",
      "  norm_type: layer_norm_sh\n",
      "  num_distance_basis: 512\n",
      "  num_heads: 8\n",
      "  num_layers: 12\n",
      "  num_sphere_samples: 128\n",
      "  otf_graph: true\n",
      "  proj_drop: 0.0\n",
      "  regress_forces: false\n",
      "  share_atom_edge_embedding: false\n",
      "  sphere_channels: 128\n",
      "  use_atom_edge_embedding: true\n",
      "  use_attn_renorm: true\n",
      "  use_gate_act: false\n",
      "  use_grid_mlp: true\n",
      "  use_pbc: false\n",
      "  use_s2_act_attn: false\n",
      "  use_sep_s2_act: true\n",
      "  weight_init: uniform\n",
      "noddp: false\n",
      "optim:\n",
      "  batch_size: 4\n",
      "  clip_grad_norm: 100\n",
      "  ema_decay: 0.999\n",
      "  eval_batch_size: 4\n",
      "  eval_every: 5000\n",
      "  lr_initial: 0.0004\n",
      "  max_epochs: 10\n",
      "  num_workers: 1\n",
      "  optimizer: AdamW\n",
      "  optimizer_params:\n",
      "    weight_decay: 0.001\n",
      "  scheduler: LambdaLR\n",
      "  scheduler_params:\n",
      "    lambda_type: cosine\n",
      "    lr_min_factor: 0.01\n",
      "    warmup_epochs: 0.1\n",
      "    warmup_factor: 0.2\n",
      "outputs:\n",
      "  energy:\n",
      "    level: molecule\n",
      "    shape: 1\n",
      "relax_dataset: {}\n",
      "slurm: {}\n",
      "task: {}\n",
      "test_dataset:\n",
      "  a2g_args:\n",
      "    r_data_keys:\n",
      "    - S1_exc\n",
      "    r_energy: false\n",
      "    r_forces: false\n",
      "  format: ase_db\n",
      "  include_relaxed_energy: false\n",
      "  keep_in_memory: false\n",
      "  key_mapping:\n",
      "    S1_exc: energy\n",
      "  src: /media/mohammed/Work/FORMED_ML/formed_test.db\n",
      "trainer: s2ef\n",
      "val_dataset:\n",
      "  a2g_args:\n",
      "    r_data_keys:\n",
      "    - S1_exc\n",
      "    r_energy: false\n",
      "    r_forces: false\n",
      "  format: ase_db\n",
      "  include_relaxed_energy: false\n",
      "  keep_in_memory: false\n",
      "  key_mapping:\n",
      "    S1_exc: energy\n",
      "  src: /media/mohammed/Work/FORMED_ML/val/formed_val.db\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:13 (ERROR): Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohammed-azzouzi15\u001b[0m (\u001b[33mazzouzi_lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./logs/wandb/2024-09-14-00-04-48/wandb/run-20240914_000513-2024-09-14-00-04-48</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/azzouzi_lab/FORMED_ML/runs/2024-09-14-00-04-48' target=\"_blank\">2024-09-14-00-04-48</a></strong> to <a href='https://wandb.ai/azzouzi_lab/FORMED_ML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/azzouzi_lab/FORMED_ML' target=\"_blank\">https://wandb.ai/azzouzi_lab/FORMED_ML</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/azzouzi_lab/FORMED_ML/runs/2024-09-14-00-04-48' target=\"_blank\">https://wandb.ai/azzouzi_lab/FORMED_ML/runs/2024-09-14-00-04-48</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:14 (INFO): Loading dataset: ase_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:20 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('/media/mohammed/Work/FORMED_ML/train/formed_train.db')]'\n",
      "2024-09-14 00:05:20 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.\n",
      "2024-09-14 00:05:20 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:20 (INFO): rank: 0: Sampler created...\n",
      "2024-09-14 00:05:20 (INFO): Created BalancedBatchSampler with sampler=<fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7b5056601cd0>, batch_size=4, drop_last=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:20 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('/media/mohammed/Work/FORMED_ML/val/formed_val.db')]'\n",
      "2024-09-14 00:05:20 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.\n",
      "2024-09-14 00:05:20 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:20 (INFO): rank: 0: Sampler created...\n",
      "2024-09-14 00:05:20 (INFO): Created BalancedBatchSampler with sampler=<fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7b50567ea290>, batch_size=4, drop_last=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:21 (WARNING): Could not find dataset metadata.npz files in '[PosixPath('/media/mohammed/Work/FORMED_ML/formed_test.db')]'\n",
      "2024-09-14 00:05:21 (WARNING): Disabled BalancedBatchSampler because num_replicas=1.\n",
      "2024-09-14 00:05:21 (WARNING): Failed to get data sizes, falling back to uniform partitioning. BalancedBatchSampler requires a dataset that has a metadata attributed with number of atoms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:21 (INFO): rank: 0: Sampler created...\n",
      "2024-09-14 00:05:21 (INFO): Created BalancedBatchSampler with sampler=<fairchem.core.common.data_parallel.StatefulDistributedSampler object at 0x7b504ef34110>, batch_size=4, drop_last=False\n",
      "2024-09-14 00:05:21 (INFO): Loading model: equiformer_v2\n",
      "2024-09-14 00:05:22 (INFO): Loaded EquiformerV2 with 77182465 parameters.\n",
      "{'energy': {'fn': 'mae'}}\n",
      "2024-09-14 00:05:22 (INFO): Parameters without weight decay:\n",
      "2024-09-14 00:05:22 (INFO): ['edge_degree_embedding.rad_func.net.0.bias', 'edge_degree_embedding.rad_func.net.1.weight', 'edge_degree_embedding.rad_func.net.1.bias', 'edge_degree_embedding.rad_func.net.3.bias', 'edge_degree_embedding.rad_func.net.4.weight', 'edge_degree_embedding.rad_func.net.4.bias', 'edge_degree_embedding.rad_func.net.6.bias', 'blocks.0.norm_1.affine_weight', 'blocks.0.norm_1.norm_l0.weight', 'blocks.0.norm_1.norm_l0.bias', 'blocks.0.ga.so2_conv_1.fc_m0.bias', 'blocks.0.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.0.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.0.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.0.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.0.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.0.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.0.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.0.ga.alpha_norm.weight', 'blocks.0.ga.alpha_norm.bias', 'blocks.0.ga.so2_conv_2.fc_m0.bias', 'blocks.0.ga.proj.bias', 'blocks.0.norm_2.affine_weight', 'blocks.0.norm_2.norm_l0.weight', 'blocks.0.norm_2.norm_l0.bias', 'blocks.0.ffn.so3_linear_1.bias', 'blocks.0.ffn.scalar_mlp.0.bias', 'blocks.0.ffn.so3_linear_2.bias', 'blocks.1.norm_1.affine_weight', 'blocks.1.norm_1.norm_l0.weight', 'blocks.1.norm_1.norm_l0.bias', 'blocks.1.ga.so2_conv_1.fc_m0.bias', 'blocks.1.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.1.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.1.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.1.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.1.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.1.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.1.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.1.ga.alpha_norm.weight', 'blocks.1.ga.alpha_norm.bias', 'blocks.1.ga.so2_conv_2.fc_m0.bias', 'blocks.1.ga.proj.bias', 'blocks.1.norm_2.affine_weight', 'blocks.1.norm_2.norm_l0.weight', 'blocks.1.norm_2.norm_l0.bias', 'blocks.1.ffn.so3_linear_1.bias', 'blocks.1.ffn.scalar_mlp.0.bias', 'blocks.1.ffn.so3_linear_2.bias', 'blocks.2.norm_1.affine_weight', 'blocks.2.norm_1.norm_l0.weight', 'blocks.2.norm_1.norm_l0.bias', 'blocks.2.ga.so2_conv_1.fc_m0.bias', 'blocks.2.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.2.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.2.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.2.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.2.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.2.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.2.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.2.ga.alpha_norm.weight', 'blocks.2.ga.alpha_norm.bias', 'blocks.2.ga.so2_conv_2.fc_m0.bias', 'blocks.2.ga.proj.bias', 'blocks.2.norm_2.affine_weight', 'blocks.2.norm_2.norm_l0.weight', 'blocks.2.norm_2.norm_l0.bias', 'blocks.2.ffn.so3_linear_1.bias', 'blocks.2.ffn.scalar_mlp.0.bias', 'blocks.2.ffn.so3_linear_2.bias', 'blocks.3.norm_1.affine_weight', 'blocks.3.norm_1.norm_l0.weight', 'blocks.3.norm_1.norm_l0.bias', 'blocks.3.ga.so2_conv_1.fc_m0.bias', 'blocks.3.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.3.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.3.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.3.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.3.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.3.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.3.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.3.ga.alpha_norm.weight', 'blocks.3.ga.alpha_norm.bias', 'blocks.3.ga.so2_conv_2.fc_m0.bias', 'blocks.3.ga.proj.bias', 'blocks.3.norm_2.affine_weight', 'blocks.3.norm_2.norm_l0.weight', 'blocks.3.norm_2.norm_l0.bias', 'blocks.3.ffn.so3_linear_1.bias', 'blocks.3.ffn.scalar_mlp.0.bias', 'blocks.3.ffn.so3_linear_2.bias', 'blocks.4.norm_1.affine_weight', 'blocks.4.norm_1.norm_l0.weight', 'blocks.4.norm_1.norm_l0.bias', 'blocks.4.ga.so2_conv_1.fc_m0.bias', 'blocks.4.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.4.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.4.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.4.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.4.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.4.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.4.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.4.ga.alpha_norm.weight', 'blocks.4.ga.alpha_norm.bias', 'blocks.4.ga.so2_conv_2.fc_m0.bias', 'blocks.4.ga.proj.bias', 'blocks.4.norm_2.affine_weight', 'blocks.4.norm_2.norm_l0.weight', 'blocks.4.norm_2.norm_l0.bias', 'blocks.4.ffn.so3_linear_1.bias', 'blocks.4.ffn.scalar_mlp.0.bias', 'blocks.4.ffn.so3_linear_2.bias', 'blocks.5.norm_1.affine_weight', 'blocks.5.norm_1.norm_l0.weight', 'blocks.5.norm_1.norm_l0.bias', 'blocks.5.ga.so2_conv_1.fc_m0.bias', 'blocks.5.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.5.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.5.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.5.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.5.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.5.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.5.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.5.ga.alpha_norm.weight', 'blocks.5.ga.alpha_norm.bias', 'blocks.5.ga.so2_conv_2.fc_m0.bias', 'blocks.5.ga.proj.bias', 'blocks.5.norm_2.affine_weight', 'blocks.5.norm_2.norm_l0.weight', 'blocks.5.norm_2.norm_l0.bias', 'blocks.5.ffn.so3_linear_1.bias', 'blocks.5.ffn.scalar_mlp.0.bias', 'blocks.5.ffn.so3_linear_2.bias', 'blocks.6.norm_1.affine_weight', 'blocks.6.norm_1.norm_l0.weight', 'blocks.6.norm_1.norm_l0.bias', 'blocks.6.ga.so2_conv_1.fc_m0.bias', 'blocks.6.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.6.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.6.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.6.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.6.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.6.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.6.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.6.ga.alpha_norm.weight', 'blocks.6.ga.alpha_norm.bias', 'blocks.6.ga.so2_conv_2.fc_m0.bias', 'blocks.6.ga.proj.bias', 'blocks.6.norm_2.affine_weight', 'blocks.6.norm_2.norm_l0.weight', 'blocks.6.norm_2.norm_l0.bias', 'blocks.6.ffn.so3_linear_1.bias', 'blocks.6.ffn.scalar_mlp.0.bias', 'blocks.6.ffn.so3_linear_2.bias', 'blocks.7.norm_1.affine_weight', 'blocks.7.norm_1.norm_l0.weight', 'blocks.7.norm_1.norm_l0.bias', 'blocks.7.ga.so2_conv_1.fc_m0.bias', 'blocks.7.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.7.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.7.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.7.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.7.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.7.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.7.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.7.ga.alpha_norm.weight', 'blocks.7.ga.alpha_norm.bias', 'blocks.7.ga.so2_conv_2.fc_m0.bias', 'blocks.7.ga.proj.bias', 'blocks.7.norm_2.affine_weight', 'blocks.7.norm_2.norm_l0.weight', 'blocks.7.norm_2.norm_l0.bias', 'blocks.7.ffn.so3_linear_1.bias', 'blocks.7.ffn.scalar_mlp.0.bias', 'blocks.7.ffn.so3_linear_2.bias', 'blocks.8.norm_1.affine_weight', 'blocks.8.norm_1.norm_l0.weight', 'blocks.8.norm_1.norm_l0.bias', 'blocks.8.ga.so2_conv_1.fc_m0.bias', 'blocks.8.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.8.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.8.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.8.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.8.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.8.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.8.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.8.ga.alpha_norm.weight', 'blocks.8.ga.alpha_norm.bias', 'blocks.8.ga.so2_conv_2.fc_m0.bias', 'blocks.8.ga.proj.bias', 'blocks.8.norm_2.affine_weight', 'blocks.8.norm_2.norm_l0.weight', 'blocks.8.norm_2.norm_l0.bias', 'blocks.8.ffn.so3_linear_1.bias', 'blocks.8.ffn.scalar_mlp.0.bias', 'blocks.8.ffn.so3_linear_2.bias', 'blocks.9.norm_1.affine_weight', 'blocks.9.norm_1.norm_l0.weight', 'blocks.9.norm_1.norm_l0.bias', 'blocks.9.ga.so2_conv_1.fc_m0.bias', 'blocks.9.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.9.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.9.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.9.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.9.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.9.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.9.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.9.ga.alpha_norm.weight', 'blocks.9.ga.alpha_norm.bias', 'blocks.9.ga.so2_conv_2.fc_m0.bias', 'blocks.9.ga.proj.bias', 'blocks.9.norm_2.affine_weight', 'blocks.9.norm_2.norm_l0.weight', 'blocks.9.norm_2.norm_l0.bias', 'blocks.9.ffn.so3_linear_1.bias', 'blocks.9.ffn.scalar_mlp.0.bias', 'blocks.9.ffn.so3_linear_2.bias', 'blocks.10.norm_1.affine_weight', 'blocks.10.norm_1.norm_l0.weight', 'blocks.10.norm_1.norm_l0.bias', 'blocks.10.ga.so2_conv_1.fc_m0.bias', 'blocks.10.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.10.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.10.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.10.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.10.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.10.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.10.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.10.ga.alpha_norm.weight', 'blocks.10.ga.alpha_norm.bias', 'blocks.10.ga.so2_conv_2.fc_m0.bias', 'blocks.10.ga.proj.bias', 'blocks.10.norm_2.affine_weight', 'blocks.10.norm_2.norm_l0.weight', 'blocks.10.norm_2.norm_l0.bias', 'blocks.10.ffn.so3_linear_1.bias', 'blocks.10.ffn.scalar_mlp.0.bias', 'blocks.10.ffn.so3_linear_2.bias', 'blocks.11.norm_1.affine_weight', 'blocks.11.norm_1.norm_l0.weight', 'blocks.11.norm_1.norm_l0.bias', 'blocks.11.ga.so2_conv_1.fc_m0.bias', 'blocks.11.ga.so2_conv_1.rad_func.net.0.bias', 'blocks.11.ga.so2_conv_1.rad_func.net.1.weight', 'blocks.11.ga.so2_conv_1.rad_func.net.1.bias', 'blocks.11.ga.so2_conv_1.rad_func.net.3.bias', 'blocks.11.ga.so2_conv_1.rad_func.net.4.weight', 'blocks.11.ga.so2_conv_1.rad_func.net.4.bias', 'blocks.11.ga.so2_conv_1.rad_func.net.6.bias', 'blocks.11.ga.alpha_norm.weight', 'blocks.11.ga.alpha_norm.bias', 'blocks.11.ga.so2_conv_2.fc_m0.bias', 'blocks.11.ga.proj.bias', 'blocks.11.norm_2.affine_weight', 'blocks.11.norm_2.norm_l0.weight', 'blocks.11.norm_2.norm_l0.bias', 'blocks.11.ffn.so3_linear_1.bias', 'blocks.11.ffn.scalar_mlp.0.bias', 'blocks.11.ffn.so3_linear_2.bias', 'norm.affine_weight', 'norm.norm_l0.weight', 'norm.norm_l0.bias', 'energy_block.so3_linear_1.bias', 'energy_block.scalar_mlp.0.bias', 'energy_block.so3_linear_2.bias']\n",
      "2024-09-14 00:05:22 (INFO): Total time taken: 7.152557373046875e-06\n",
      "2024-09-14 00:05:25 (INFO): energy_mae: 3.89e+00, energy_mse: 1.58e+01, loss: 3.89e+00, lr: 8.12e-05, epoch: 4.23e-04, step: 1.00e+01\n",
      "2024-09-14 00:05:27 (INFO): energy_mae: 3.47e+00, energy_mse: 1.33e+01, loss: 3.47e+00, lr: 8.26e-05, epoch: 8.47e-04, step: 2.00e+01\n",
      "2024-09-14 00:05:29 (INFO): energy_mae: 3.38e+00, energy_mse: 1.23e+01, loss: 3.38e+00, lr: 8.39e-05, epoch: 1.27e-03, step: 3.00e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 1 is less than current step: 8. Dropping entry: {'train/grad_norm': 1.901077151298523, '_timestamp': 1726265123.1787603}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 1 is less than current step: 8. Dropping entry: {'train/energy_mae': 4.21744966506958, 'train/energy_mse': 18.143144607543945, 'train/loss': 4.21744966506958, 'train/lr': 8e-05, 'train/epoch': 4.233879503789322e-05, 'train/step': 1, '_timestamp': 1726265123.2019079}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 2 is less than current step: 8. Dropping entry: {'train/grad_norm': 2.681767463684082, '_timestamp': 1726265123.4360397}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 2 is less than current step: 8. Dropping entry: {'train/energy_mae': 4.182177543640137, 'train/energy_mse': 17.69871425628662, 'train/loss': 4.182177543640137, 'train/lr': 8.013553578991953e-05, 'train/epoch': 8.467759007578644e-05, 'train/step': 2, '_timestamp': 1726265123.4415245}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 3 is less than current step: 8. Dropping entry: {'train/grad_norm': 2.911367416381836, '_timestamp': 1726265123.6725566}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 3 is less than current step: 8. Dropping entry: {'train/energy_mae': 4.107482512791951, 'train/energy_mse': 17.058419545491535, 'train/loss': 4.107482512791951, 'train/lr': 8.027107157983905e-05, 'train/epoch': 0.00012701638511367967, 'train/step': 3, '_timestamp': 1726265123.678143}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 4 is less than current step: 8. Dropping entry: {'train/grad_norm': 3.5977284908294678, '_timestamp': 1726265123.9438689}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 4 is less than current step: 8. Dropping entry: {'train/energy_mae': 3.838378608226776, 'train/energy_mse': 15.210630416870117, 'train/loss': 3.838378608226776, 'train/lr': 8.040660736975859e-05, 'train/epoch': 0.00016935518015157288, 'train/step': 4, '_timestamp': 1726265123.9494932}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 5 is less than current step: 8. Dropping entry: {'train/grad_norm': 2.3809969425201416, '_timestamp': 1726265124.107236}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 5 is less than current step: 8. Dropping entry: {'train/energy_mae': 3.87804274559021, 'train/energy_mse': 15.761344909667969, 'train/loss': 3.87804274559021, 'train/lr': 8.054214315967811e-05, 'train/epoch': 0.00021169397518946612, 'train/step': 5, '_timestamp': 1726265124.1308427}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 6 is less than current step: 8. Dropping entry: {'train/grad_norm': 2.6860175132751465, '_timestamp': 1726265124.2931056}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 6 is less than current step: 8. Dropping entry: {'train/energy_mae': 3.8609991470972695, 'train/energy_mse': 15.571161270141602, 'train/loss': 3.8609991470972695, 'train/lr': 8.067767894959765e-05, 'train/epoch': 0.00025403277022735933, 'train/step': 6, '_timestamp': 1726265124.317459}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 7 is less than current step: 8. Dropping entry: {'train/grad_norm': 2.9817395210266113, '_timestamp': 1726265124.4907253}).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 7 is less than current step: 8. Dropping entry: {'train/energy_mae': 3.8019121374402727, 'train/energy_mse': 15.057204110281807, 'train/loss': 3.8019121374402727, 'train/lr': 8.081321473951716e-05, 'train/epoch': 0.00029637156526525255, 'train/step': 7, '_timestamp': 1726265124.516878}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-14 00:05:31 (INFO): energy_mae: 3.03e+00, energy_mse: 1.09e+01, loss: 3.03e+00, lr: 8.53e-05, epoch: 1.69e-03, step: 4.00e+01\n",
      "2024-09-14 00:05:34 (INFO): energy_mae: 2.28e+00, energy_mse: 6.27e+00, loss: 2.28e+00, lr: 8.66e-05, epoch: 2.12e-03, step: 5.00e+01\n",
      "2024-09-14 00:05:36 (INFO): energy_mae: 2.53e+00, energy_mse: 7.73e+00, loss: 2.53e+00, lr: 8.80e-05, epoch: 2.54e-03, step: 6.00e+01\n",
      "2024-09-14 00:05:38 (INFO): energy_mae: 1.98e+00, energy_mse: 5.34e+00, loss: 1.98e+00, lr: 8.94e-05, epoch: 2.96e-03, step: 7.00e+01\n",
      "2024-09-14 00:05:40 (INFO): energy_mae: 2.11e+00, energy_mse: 5.80e+00, loss: 2.11e+00, lr: 9.07e-05, epoch: 3.39e-03, step: 8.00e+01\n",
      "2024-09-14 00:05:42 (INFO): energy_mae: 1.89e+00, energy_mse: 5.41e+00, loss: 1.89e+00, lr: 9.21e-05, epoch: 3.81e-03, step: 9.00e+01\n",
      "2024-09-14 00:05:44 (INFO): energy_mae: 2.07e+00, energy_mse: 5.66e+00, loss: 2.07e+00, lr: 9.34e-05, epoch: 4.23e-03, step: 1.00e+02\n",
      "2024-09-14 00:05:46 (INFO): energy_mae: 1.88e+00, energy_mse: 4.54e+00, loss: 1.88e+00, lr: 9.48e-05, epoch: 4.66e-03, step: 1.10e+02\n",
      "2024-09-14 00:05:49 (INFO): energy_mae: 1.45e+00, energy_mse: 3.32e+00, loss: 1.45e+00, lr: 9.61e-05, epoch: 5.08e-03, step: 1.20e+02\n",
      "2024-09-14 00:05:51 (INFO): energy_mae: 1.41e+00, energy_mse: 3.03e+00, loss: 1.41e+00, lr: 9.75e-05, epoch: 5.50e-03, step: 1.30e+02\n",
      "2024-09-14 00:05:53 (INFO): energy_mae: 1.45e+00, energy_mse: 3.21e+00, loss: 1.45e+00, lr: 9.88e-05, epoch: 5.93e-03, step: 1.40e+02\n",
      "2024-09-14 00:05:56 (INFO): energy_mae: 1.46e+00, energy_mse: 3.00e+00, loss: 1.46e+00, lr: 1.00e-04, epoch: 6.35e-03, step: 1.50e+02\n",
      "2024-09-14 00:05:58 (INFO): energy_mae: 1.50e+00, energy_mse: 3.26e+00, loss: 1.50e+00, lr: 1.02e-04, epoch: 6.77e-03, step: 1.60e+02\n",
      "2024-09-14 00:06:00 (INFO): energy_mae: 1.38e+00, energy_mse: 3.10e+00, loss: 1.38e+00, lr: 1.03e-04, epoch: 7.20e-03, step: 1.70e+02\n",
      "2024-09-14 00:06:02 (INFO): energy_mae: 1.63e+00, energy_mse: 4.04e+00, loss: 1.63e+00, lr: 1.04e-04, epoch: 7.62e-03, step: 1.80e+02\n",
      "2024-09-14 00:06:05 (INFO): energy_mae: 1.60e+00, energy_mse: 4.65e+00, loss: 1.60e+00, lr: 1.06e-04, epoch: 8.04e-03, step: 1.90e+02\n",
      "2024-09-14 00:06:07 (INFO): energy_mae: 1.63e+00, energy_mse: 3.99e+00, loss: 1.63e+00, lr: 1.07e-04, epoch: 8.47e-03, step: 2.00e+02\n",
      "2024-09-14 00:06:09 (INFO): energy_mae: 1.16e+00, energy_mse: 2.28e+00, loss: 1.16e+00, lr: 1.08e-04, epoch: 8.89e-03, step: 2.10e+02\n",
      "2024-09-14 00:06:12 (INFO): energy_mae: 1.43e+00, energy_mse: 3.30e+00, loss: 1.43e+00, lr: 1.10e-04, epoch: 9.31e-03, step: 2.20e+02\n",
      "2024-09-14 00:06:14 (INFO): energy_mae: 1.42e+00, energy_mse: 3.85e+00, loss: 1.42e+00, lr: 1.11e-04, epoch: 9.74e-03, step: 2.30e+02\n",
      "2024-09-14 00:06:17 (INFO): energy_mae: 1.25e+00, energy_mse: 2.35e+00, loss: 1.25e+00, lr: 1.12e-04, epoch: 1.02e-02, step: 2.40e+02\n",
      "2024-09-14 00:06:19 (INFO): energy_mae: 1.55e+00, energy_mse: 3.59e+00, loss: 1.55e+00, lr: 1.14e-04, epoch: 1.06e-02, step: 2.50e+02\n",
      "2024-09-14 00:06:21 (INFO): energy_mae: 1.38e+00, energy_mse: 3.50e+00, loss: 1.38e+00, lr: 1.15e-04, epoch: 1.10e-02, step: 2.60e+02\n",
      "2024-09-14 00:06:23 (INFO): energy_mae: 1.47e+00, energy_mse: 3.94e+00, loss: 1.47e+00, lr: 1.16e-04, epoch: 1.14e-02, step: 2.70e+02\n",
      "2024-09-14 00:06:25 (INFO): energy_mae: 1.63e+00, energy_mse: 4.06e+00, loss: 1.63e+00, lr: 1.18e-04, epoch: 1.19e-02, step: 2.80e+02\n",
      "2024-09-14 00:06:27 (INFO): energy_mae: 1.39e+00, energy_mse: 3.38e+00, loss: 1.39e+00, lr: 1.19e-04, epoch: 1.23e-02, step: 2.90e+02\n",
      "2024-09-14 00:06:30 (INFO): energy_mae: 1.57e+00, energy_mse: 3.58e+00, loss: 1.57e+00, lr: 1.21e-04, epoch: 1.27e-02, step: 3.00e+02\n",
      "2024-09-14 00:06:32 (INFO): energy_mae: 1.21e+00, energy_mse: 2.10e+00, loss: 1.21e+00, lr: 1.22e-04, epoch: 1.31e-02, step: 3.10e+02\n",
      "2024-09-14 00:06:34 (INFO): energy_mae: 1.28e+00, energy_mse: 2.45e+00, loss: 1.28e+00, lr: 1.23e-04, epoch: 1.35e-02, step: 3.20e+02\n",
      "2024-09-14 00:06:37 (INFO): energy_mae: 1.14e+00, energy_mse: 2.05e+00, loss: 1.14e+00, lr: 1.25e-04, epoch: 1.40e-02, step: 3.30e+02\n",
      "2024-09-14 00:06:39 (INFO): energy_mae: 1.29e+00, energy_mse: 2.35e+00, loss: 1.29e+00, lr: 1.26e-04, epoch: 1.44e-02, step: 3.40e+02\n",
      "2024-09-14 00:06:41 (INFO): energy_mae: 1.35e+00, energy_mse: 3.44e+00, loss: 1.35e+00, lr: 1.27e-04, epoch: 1.48e-02, step: 3.50e+02\n",
      "2024-09-14 00:06:43 (INFO): energy_mae: 1.05e+00, energy_mse: 1.58e+00, loss: 1.05e+00, lr: 1.29e-04, epoch: 1.52e-02, step: 3.60e+02\n",
      "2024-09-14 00:06:45 (INFO): energy_mae: 1.23e+00, energy_mse: 2.00e+00, loss: 1.23e+00, lr: 1.30e-04, epoch: 1.57e-02, step: 3.70e+02\n",
      "2024-09-14 00:06:48 (INFO): energy_mae: 1.32e+00, energy_mse: 3.18e+00, loss: 1.32e+00, lr: 1.31e-04, epoch: 1.61e-02, step: 3.80e+02\n",
      "2024-09-14 00:06:50 (INFO): energy_mae: 1.19e+00, energy_mse: 2.22e+00, loss: 1.19e+00, lr: 1.33e-04, epoch: 1.65e-02, step: 3.90e+02\n",
      "2024-09-14 00:06:52 (INFO): energy_mae: 1.20e+00, energy_mse: 1.98e+00, loss: 1.20e+00, lr: 1.34e-04, epoch: 1.69e-02, step: 4.00e+02\n",
      "2024-09-14 00:06:55 (INFO): energy_mae: 1.33e+00, energy_mse: 2.69e+00, loss: 1.33e+00, lr: 1.35e-04, epoch: 1.74e-02, step: 4.10e+02\n",
      "2024-09-14 00:06:57 (INFO): energy_mae: 1.09e+00, energy_mse: 1.77e+00, loss: 1.09e+00, lr: 1.37e-04, epoch: 1.78e-02, step: 4.20e+02\n",
      "2024-09-14 00:06:59 (INFO): energy_mae: 1.17e+00, energy_mse: 2.61e+00, loss: 1.17e+00, lr: 1.38e-04, epoch: 1.82e-02, step: 4.30e+02\n",
      "2024-09-14 00:07:02 (INFO): energy_mae: 9.62e-01, energy_mse: 1.47e+00, loss: 9.62e-01, lr: 1.40e-04, epoch: 1.86e-02, step: 4.40e+02\n",
      "2024-09-14 00:07:04 (INFO): energy_mae: 1.40e+00, energy_mse: 3.34e+00, loss: 1.40e+00, lr: 1.41e-04, epoch: 1.91e-02, step: 4.50e+02\n",
      "2024-09-14 00:07:06 (INFO): energy_mae: 8.67e-01, energy_mse: 1.15e+00, loss: 8.67e-01, lr: 1.42e-04, epoch: 1.95e-02, step: 4.60e+02\n",
      "2024-09-14 00:07:08 (INFO): energy_mae: 1.07e+00, energy_mse: 1.77e+00, loss: 1.07e+00, lr: 1.44e-04, epoch: 1.99e-02, step: 4.70e+02\n",
      "2024-09-14 00:07:10 (INFO): energy_mae: 8.96e-01, energy_mse: 1.26e+00, loss: 8.96e-01, lr: 1.45e-04, epoch: 2.03e-02, step: 4.80e+02\n",
      "2024-09-14 00:07:12 (INFO): energy_mae: 1.10e+00, energy_mse: 2.11e+00, loss: 1.10e+00, lr: 1.46e-04, epoch: 2.07e-02, step: 4.90e+02\n",
      "2024-09-14 00:07:15 (INFO): energy_mae: 1.02e+00, energy_mse: 1.61e+00, loss: 1.02e+00, lr: 1.48e-04, epoch: 2.12e-02, step: 5.00e+02\n",
      "2024-09-14 00:07:17 (INFO): energy_mae: 8.75e-01, energy_mse: 1.55e+00, loss: 8.75e-01, lr: 1.49e-04, epoch: 2.16e-02, step: 5.10e+02\n",
      "2024-09-14 00:07:20 (INFO): energy_mae: 9.90e-01, energy_mse: 1.59e+00, loss: 9.90e-01, lr: 1.50e-04, epoch: 2.20e-02, step: 5.20e+02\n",
      "2024-09-14 00:07:22 (INFO): energy_mae: 9.34e-01, energy_mse: 1.56e+00, loss: 9.34e-01, lr: 1.52e-04, epoch: 2.24e-02, step: 5.30e+02\n",
      "2024-09-14 00:07:24 (INFO): energy_mae: 1.23e+00, energy_mse: 2.68e+00, loss: 1.23e+00, lr: 1.53e-04, epoch: 2.29e-02, step: 5.40e+02\n",
      "2024-09-14 00:07:26 (INFO): energy_mae: 1.20e+00, energy_mse: 2.48e+00, loss: 1.20e+00, lr: 1.54e-04, epoch: 2.33e-02, step: 5.50e+02\n",
      "2024-09-14 00:07:28 (INFO): energy_mae: 1.24e+00, energy_mse: 2.42e+00, loss: 1.24e+00, lr: 1.56e-04, epoch: 2.37e-02, step: 5.60e+02\n",
      "2024-09-14 00:07:31 (INFO): energy_mae: 1.21e+00, energy_mse: 2.29e+00, loss: 1.21e+00, lr: 1.57e-04, epoch: 2.41e-02, step: 5.70e+02\n",
      "2024-09-14 00:07:33 (INFO): energy_mae: 1.09e+00, energy_mse: 1.85e+00, loss: 1.09e+00, lr: 1.58e-04, epoch: 2.46e-02, step: 5.80e+02\n",
      "2024-09-14 00:07:35 (INFO): energy_mae: 9.93e-01, energy_mse: 1.68e+00, loss: 9.93e-01, lr: 1.60e-04, epoch: 2.50e-02, step: 5.90e+02\n",
      "2024-09-14 00:07:37 (INFO): energy_mae: 1.08e+00, energy_mse: 2.16e+00, loss: 1.08e+00, lr: 1.61e-04, epoch: 2.54e-02, step: 6.00e+02\n",
      "2024-09-14 00:07:39 (INFO): energy_mae: 8.11e-01, energy_mse: 1.08e+00, loss: 8.11e-01, lr: 1.63e-04, epoch: 2.58e-02, step: 6.10e+02\n",
      "2024-09-14 00:07:41 (INFO): energy_mae: 8.45e-01, energy_mse: 1.01e+00, loss: 8.45e-01, lr: 1.64e-04, epoch: 2.63e-02, step: 6.20e+02\n",
      "2024-09-14 00:07:44 (INFO): energy_mae: 9.05e-01, energy_mse: 1.81e+00, loss: 9.05e-01, lr: 1.65e-04, epoch: 2.67e-02, step: 6.30e+02\n",
      "2024-09-14 00:07:46 (INFO): energy_mae: 9.55e-01, energy_mse: 1.80e+00, loss: 9.55e-01, lr: 1.67e-04, epoch: 2.71e-02, step: 6.40e+02\n",
      "2024-09-14 00:07:48 (INFO): energy_mae: 8.32e-01, energy_mse: 1.32e+00, loss: 8.32e-01, lr: 1.68e-04, epoch: 2.75e-02, step: 6.50e+02\n",
      "2024-09-14 00:07:50 (INFO): energy_mae: 7.90e-01, energy_mse: 1.01e+00, loss: 7.90e-01, lr: 1.69e-04, epoch: 2.79e-02, step: 6.60e+02\n",
      "2024-09-14 00:07:53 (INFO): energy_mae: 9.39e-01, energy_mse: 1.46e+00, loss: 9.39e-01, lr: 1.71e-04, epoch: 2.84e-02, step: 6.70e+02\n",
      "2024-09-14 00:07:55 (INFO): energy_mae: 9.43e-01, energy_mse: 1.61e+00, loss: 9.43e-01, lr: 1.72e-04, epoch: 2.88e-02, step: 6.80e+02\n",
      "2024-09-14 00:07:57 (INFO): energy_mae: 7.77e-01, energy_mse: 8.34e-01, loss: 7.77e-01, lr: 1.73e-04, epoch: 2.92e-02, step: 6.90e+02\n",
      "2024-09-14 00:07:59 (INFO): energy_mae: 1.05e+00, energy_mse: 1.86e+00, loss: 1.05e+00, lr: 1.75e-04, epoch: 2.96e-02, step: 7.00e+02\n",
      "2024-09-14 00:08:02 (INFO): energy_mae: 7.61e-01, energy_mse: 8.48e-01, loss: 7.61e-01, lr: 1.76e-04, epoch: 3.01e-02, step: 7.10e+02\n",
      "2024-09-14 00:08:04 (INFO): energy_mae: 8.12e-01, energy_mse: 9.90e-01, loss: 8.12e-01, lr: 1.77e-04, epoch: 3.05e-02, step: 7.20e+02\n",
      "2024-09-14 00:08:06 (INFO): energy_mae: 9.43e-01, energy_mse: 1.35e+00, loss: 9.43e-01, lr: 1.79e-04, epoch: 3.09e-02, step: 7.30e+02\n",
      "2024-09-14 00:08:08 (INFO): energy_mae: 1.09e+00, energy_mse: 2.28e+00, loss: 1.09e+00, lr: 1.80e-04, epoch: 3.13e-02, step: 7.40e+02\n",
      "2024-09-14 00:08:11 (INFO): energy_mae: 9.42e-01, energy_mse: 1.65e+00, loss: 9.42e-01, lr: 1.82e-04, epoch: 3.18e-02, step: 7.50e+02\n",
      "2024-09-14 00:08:13 (INFO): energy_mae: 9.18e-01, energy_mse: 1.36e+00, loss: 9.18e-01, lr: 1.83e-04, epoch: 3.22e-02, step: 7.60e+02\n",
      "2024-09-14 00:08:15 (INFO): energy_mae: 6.45e-01, energy_mse: 6.74e-01, loss: 6.45e-01, lr: 1.84e-04, epoch: 3.26e-02, step: 7.70e+02\n",
      "2024-09-14 00:08:18 (INFO): energy_mae: 9.31e-01, energy_mse: 1.25e+00, loss: 9.31e-01, lr: 1.86e-04, epoch: 3.30e-02, step: 7.80e+02\n",
      "2024-09-14 00:08:20 (INFO): energy_mae: 7.39e-01, energy_mse: 8.92e-01, loss: 7.39e-01, lr: 1.87e-04, epoch: 3.34e-02, step: 7.90e+02\n",
      "2024-09-14 00:08:22 (INFO): energy_mae: 9.22e-01, energy_mse: 1.68e+00, loss: 9.22e-01, lr: 1.88e-04, epoch: 3.39e-02, step: 8.00e+02\n",
      "2024-09-14 00:08:25 (INFO): energy_mae: 9.31e-01, energy_mse: 1.50e+00, loss: 9.31e-01, lr: 1.90e-04, epoch: 3.43e-02, step: 8.10e+02\n",
      "2024-09-14 00:08:27 (INFO): energy_mae: 8.50e-01, energy_mse: 1.24e+00, loss: 8.50e-01, lr: 1.91e-04, epoch: 3.47e-02, step: 8.20e+02\n",
      "2024-09-14 00:08:29 (INFO): energy_mae: 8.43e-01, energy_mse: 1.18e+00, loss: 8.43e-01, lr: 1.92e-04, epoch: 3.51e-02, step: 8.30e+02\n",
      "2024-09-14 00:08:32 (INFO): energy_mae: 8.65e-01, energy_mse: 1.16e+00, loss: 8.65e-01, lr: 1.94e-04, epoch: 3.56e-02, step: 8.40e+02\n",
      "2024-09-14 00:08:34 (INFO): energy_mae: 8.39e-01, energy_mse: 1.21e+00, loss: 8.39e-01, lr: 1.95e-04, epoch: 3.60e-02, step: 8.50e+02\n",
      "2024-09-14 00:08:36 (INFO): energy_mae: 8.90e-01, energy_mse: 1.29e+00, loss: 8.90e-01, lr: 1.96e-04, epoch: 3.64e-02, step: 8.60e+02\n",
      "2024-09-14 00:08:39 (INFO): energy_mae: 9.73e-01, energy_mse: 1.64e+00, loss: 9.73e-01, lr: 1.98e-04, epoch: 3.68e-02, step: 8.70e+02\n",
      "2024-09-14 00:08:41 (INFO): energy_mae: 6.92e-01, energy_mse: 8.36e-01, loss: 6.92e-01, lr: 1.99e-04, epoch: 3.73e-02, step: 8.80e+02\n",
      "2024-09-14 00:08:44 (INFO): energy_mae: 7.66e-01, energy_mse: 1.04e+00, loss: 7.66e-01, lr: 2.00e-04, epoch: 3.77e-02, step: 8.90e+02\n",
      "2024-09-14 00:08:46 (INFO): energy_mae: 7.45e-01, energy_mse: 8.38e-01, loss: 7.45e-01, lr: 2.02e-04, epoch: 3.81e-02, step: 9.00e+02\n",
      "2024-09-14 00:08:48 (INFO): energy_mae: 1.07e+00, energy_mse: 2.01e+00, loss: 1.07e+00, lr: 2.03e-04, epoch: 3.85e-02, step: 9.10e+02\n",
      "2024-09-14 00:08:50 (INFO): energy_mae: 7.67e-01, energy_mse: 1.12e+00, loss: 7.67e-01, lr: 2.05e-04, epoch: 3.90e-02, step: 9.20e+02\n",
      "2024-09-14 00:08:53 (INFO): energy_mae: 8.93e-01, energy_mse: 1.55e+00, loss: 8.93e-01, lr: 2.06e-04, epoch: 3.94e-02, step: 9.30e+02\n",
      "2024-09-14 00:08:55 (INFO): energy_mae: 8.31e-01, energy_mse: 1.12e+00, loss: 8.31e-01, lr: 2.07e-04, epoch: 3.98e-02, step: 9.40e+02\n",
      "2024-09-14 00:08:57 (INFO): energy_mae: 8.71e-01, energy_mse: 1.22e+00, loss: 8.71e-01, lr: 2.09e-04, epoch: 4.02e-02, step: 9.50e+02\n",
      "2024-09-14 00:09:00 (INFO): energy_mae: 7.95e-01, energy_mse: 1.20e+00, loss: 7.95e-01, lr: 2.10e-04, epoch: 4.06e-02, step: 9.60e+02\n",
      "2024-09-14 00:09:02 (INFO): energy_mae: 8.74e-01, energy_mse: 1.52e+00, loss: 8.74e-01, lr: 2.11e-04, epoch: 4.11e-02, step: 9.70e+02\n",
      "2024-09-14 00:09:04 (INFO): energy_mae: 1.04e+00, energy_mse: 1.83e+00, loss: 1.04e+00, lr: 2.13e-04, epoch: 4.15e-02, step: 9.80e+02\n",
      "2024-09-14 00:09:07 (INFO): energy_mae: 8.53e-01, energy_mse: 1.33e+00, loss: 8.53e-01, lr: 2.14e-04, epoch: 4.19e-02, step: 9.90e+02\n",
      "2024-09-14 00:09:09 (INFO): energy_mae: 8.31e-01, energy_mse: 9.90e-01, loss: 8.31e-01, lr: 2.15e-04, epoch: 4.23e-02, step: 1.00e+03\n",
      "2024-09-14 00:09:11 (INFO): energy_mae: 7.28e-01, energy_mse: 7.29e-01, loss: 7.28e-01, lr: 2.17e-04, epoch: 4.28e-02, step: 1.01e+03\n",
      "2024-09-14 00:09:14 (INFO): energy_mae: 8.03e-01, energy_mse: 1.04e+00, loss: 8.03e-01, lr: 2.18e-04, epoch: 4.32e-02, step: 1.02e+03\n",
      "2024-09-14 00:09:16 (INFO): energy_mae: 9.92e-01, energy_mse: 1.86e+00, loss: 9.92e-01, lr: 2.19e-04, epoch: 4.36e-02, step: 1.03e+03\n",
      "2024-09-14 00:09:18 (INFO): energy_mae: 7.35e-01, energy_mse: 1.17e+00, loss: 7.35e-01, lr: 2.21e-04, epoch: 4.40e-02, step: 1.04e+03\n",
      "2024-09-14 00:09:20 (INFO): energy_mae: 9.06e-01, energy_mse: 1.35e+00, loss: 9.06e-01, lr: 2.22e-04, epoch: 4.45e-02, step: 1.05e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-09-14 00:09:22,009] Trial 7 failed with parameters: {'num_layers': 10, 'max_neighbors': 17, 'attn_hidden_channels': 96} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_157041/4069694961.py\", line 49, in evaluation_function\n",
      "    task.run(trial)\n",
      "  File \"/tmp/ipykernel_157041/4069694961.py\", line 17, in run\n",
      "    self.trainer.train(\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/trainers/ocp_trainer.py\", line 157, in train\n",
      "    out = self._forward(batch)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/trainers/ocp_trainer.py\", line 246, in _forward\n",
      "    out = self.model(batch.to(self.device))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/common/utils.py\", line 163, in cls_method\n",
      "    return f(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/equiformer_v2.py\", line 553, in forward\n",
      "    x = self.blocks[i](\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/transformer_block.py\", line 659, in forward\n",
      "    output_embedding = self.ga(\n",
      "                       ^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/transformer_block.py\", line 287, in forward\n",
      "    x_message, x_0_extra = self.so2_conv_1(x_message, x_edge)\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/so2_ops.py\", line 154, in forward\n",
      "    x_0 = x.embedding.narrow(1, 0, self.mappingReduced.m_size[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-14 00:09:22,011] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 78\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, value))\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     55\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///optuna.db\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[1;32m     58\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m pruned_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, states\u001b[38;5;241m=\u001b[39m[TrialState\u001b[38;5;241m.\u001b[39mPRUNED])\n\u001b[1;32m     63\u001b[0m complete_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(deepcopy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, states\u001b[38;5;241m=\u001b[39m[TrialState\u001b[38;5;241m.\u001b[39mCOMPLETE])\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m, in \u001b[0;36mmain.<locals>.evaluation_function\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     47\u001b[0m task\u001b[38;5;241m.\u001b[39msetup(trainer)\n\u001b[1;32m     48\u001b[0m model_hyperparameters(trial, task\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mbest_val_metric\n",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m, in \u001b[0;36mOptunaTasks.run\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrial\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_error(e)\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/trainers/ocp_trainer.py:157\u001b[0m, in \u001b[0;36mOCPTrainer.train\u001b[0;34m(self, disable_eval_tqdm)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Forward, loss, backward.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(out, batch)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Compute metrics.\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/trainers/ocp_trainer.py:246\u001b[0m, in \u001b[0;36mOCPTrainer._forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m--> 246\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    248\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnatoms\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/common/utils.py:163\u001b[0m, in \u001b[0;36mconditional_grad.<locals>.decorator.<locals>.cls_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregress_forces \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirect_forces\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    162\u001b[0m     f \u001b[38;5;241m=\u001b[39m dec(func)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/equiformer_v2.py:553\u001b[0m, in \u001b[0;36mEquiformerV2.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m###############################################################\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Update spherical node embeddings\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m###############################################################\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m--> 553\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# SO3_Embedding\u001b[39;49;00m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic_numbers_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for GraphDropPath\u001b[39;49;00m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Final layer norm\u001b[39;00m\n\u001b[1;32m    563\u001b[0m x\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x\u001b[38;5;241m.\u001b[39membedding)\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/transformer_block.py:659\u001b[0m, in \u001b[0;36mTransBlockV2.forward\u001b[0;34m(self, x, atomic_numbers, edge_distance, edge_index, batch, node_offset)\u001b[0m\n\u001b[1;32m    657\u001b[0m x_res \u001b[38;5;241m=\u001b[39m output_embedding\u001b[38;5;241m.\u001b[39membedding\n\u001b[1;32m    658\u001b[0m output_embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_1(output_embedding\u001b[38;5;241m.\u001b[39membedding)\n\u001b[0;32m--> 659\u001b[0m output_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mga\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matomic_numbers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_offset\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    664\u001b[0m     output_embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\n\u001b[1;32m    665\u001b[0m         output_embedding\u001b[38;5;241m.\u001b[39membedding, batch\n\u001b[1;32m    666\u001b[0m     )\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/transformer_block.py:287\u001b[0m, in \u001b[0;36mSO2EquivariantGraphAttention.forward\u001b[0;34m(self, x, atomic_numbers, edge_distance, edge_index, node_offset)\u001b[0m\n\u001b[1;32m    285\u001b[0m     x_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mso2_conv_1(x_message, x_edge)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     x_message, x_0_extra \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mso2_conv_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_edge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Activation\u001b[39;00m\n\u001b[1;32m    290\u001b[0m x_alpha_num_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_alpha_channels\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/mohammed/Work/anaconda3/envs/fair-chem/lib/python3.11/site-packages/fairchem/core/models/equiformer_v2/so2_ops.py:154\u001b[0m, in \u001b[0;36mSO2_Convolution.forward\u001b[0;34m(self, x, x_edge)\u001b[0m\n\u001b[1;32m    151\u001b[0m offset_rad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Compute m=0 coefficients separately since they only have real values (no imaginary)\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnarrow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmappingReduced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m x_0\u001b[38;5;241m.\u001b[39mreshape(num_edges, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrad_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import main_fair_chem\n",
    "import argparse\n",
    "from fairchem.core.common.utils import (\n",
    "    new_trainer_context,\n",
    ")\n",
    "from OptunaTrained import OptunaTrained\n",
    "from fairchem.core.tasks.task import BaseTask\n",
    "import optuna\n",
    "from fairchem.core.common.registry import registry\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "\n",
    "@registry.register_task(\"validate\")\n",
    "class OptunaTasks(BaseTask):\n",
    "    def run(self, trial) -> None:\n",
    "        try:\n",
    "            self.trainer.train(\n",
    "                trial\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            self._process_error(e)\n",
    "            raise e\n",
    "\n",
    "\n",
    "def model_hyperparameters(trial, model):\n",
    "    model.num_layers = trial.suggest_categorical(\"num_layers\", [ 6, 8, 10, 12])\n",
    "\n",
    "    model.max_neighbors = trial.suggest_int(\"max_neighbors\", 15, 25)\n",
    "    model.attn_hidden_channels = trial.suggest_categorical(\"attn_hidden_channels\", [64,96])\n",
    "\n",
    "\n",
    "def main():\n",
    "    study_name = \"equiformer_v2\"\n",
    "\n",
    "    def evaluation_function(trial):\n",
    "        main_fair_chem.setup_logging()\n",
    "        parser: argparse.ArgumentParser = main_fair_chem.flags.get_parser()\n",
    "        args = parser.parse_args([\"--mode\", \"validate\", \"--config-yml\", \"config_files/equiformer_v2/equiformer_v2_N@12_L@6_M@2.yml\"])\n",
    "\n",
    "        # args, override_args = parser.parse_known_args()\n",
    "\n",
    "        config = main_fair_chem.build_config(args, {})\n",
    "        with new_trainer_context(config=config) as ctx:\n",
    "            config = ctx.config\n",
    "            task = ctx.task\n",
    "            trainer = ctx.trainer\n",
    "        task.setup(trainer)\n",
    "        model_hyperparameters(trial, task.trainer.model)\n",
    "        task.run(trial)\n",
    "        return task.trainer.best_val_metric\n",
    "\n",
    "\n",
    "    print(\"running\")\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        storage=\"sqlite:///optuna.db\",\n",
    "        study_name=study_name,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(evaluation_function, n_trials=2, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fair-chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
